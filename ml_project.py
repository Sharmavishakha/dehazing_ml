# -*- coding: utf-8 -*-
"""ml_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KKofKgSxFR5gCmDWi2X3ul8kMTzmlPVU
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install opencv-python-headless

import os
import cv2
import numpy as np
import skimage.util as skimg
import random

"""Hazy¬†Patch=Clear¬†Patch√ótransmission+(1‚àítransmission)"""

# in this code it is basically creating a dataset with adjusting clear images
# with random haze value and saving these images with clear and haze value
# creating a new dataset for haze mapped with haze value and dehaze image

def load_train_dataset(image_folder, count=20, patch_count=10):
    # Define transformation values
    trans_vals = [0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8]

    nyu_image_patches = None
    nyu_haze_patches = None
    nyu_random_transmission = []

    # Get list of image files in the folder
    png_files = sorted([f for f in os.listdir(image_folder) if f.endswith('.png')])
    jpg_files = sorted([f for f in os.listdir(image_folder) if f.endswith('.jpg')])

    # Select the first 'count' images
    selected_png_files = png_files[:count]
    selected_jpg_files = jpg_files[:count]

    for img_file, depth_file in zip(selected_png_files, selected_jpg_files):
        image_path = os.path.join(image_folder, img_file)
        depth_path = os.path.join(image_folder, depth_file)

        # Load the RGB image
        image = cv2.imread(image_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB
        image = image / 255.0  # Normalize to 0-1 range

        # Load the depth map
        depth_map = cv2.imread(depth_path, cv2.IMREAD_UNCHANGED)  # Load as is

        # Optionally normalize depth map if needed (e.g., by dividing by max value)
        # depth_map = depth_map / np.max(depth_map)  # Normalize depth map

        # Extract patches from the RGB image
        patches = sk_image.extract_patches_2d(image, patch_size=(16, 16), max_patches=patch_count)
        if nyu_image_patches is not None:
            nyu_image_patches = np.concatenate((nyu_image_patches, patches))
        else:
            nyu_image_patches = patches

    for image in nyu_image_patches:
        transmission = random.choice(trans_vals)
        image = image * transmission + (1 - transmission)
        nyu_random_transmission.append(transmission)
        if nyu_haze_patches is not None:
            nyu_haze_patches = np.concatenate((nyu_haze_patches, [image]))
        else:
            nyu_haze_patches = np.array([image])

    return {"clear_image_patch": nyu_image_patches, "transmission_values": nyu_random_transmission, "haze_image_patch": nyu_haze_patches}

image_folder = '/content/drive/My Drive/DL Project/TrainData'

!pip install opencv-python-headless scikit-image

import os
import cv2
import numpy as np
from sklearn.feature_extraction import image as sk_image
import random

d = load_train_dataset(image_folder, count=20, patch_count=30)

# This function prepares and saves the training dataset in a highly optimized
# format for later use in machine learning models

def create_train_dataset(count=20, patch_count=10, comp=9, shuff=True):
    start_time = time.time()
    image_folder = '/content/drive/My Drive/DL Project/TrainData'
    d = load_train_dataset(image_folder, count, patch_count)
    print("--- %s seconds in creating dictionary ---" % (time.time() - start_time))
    print("Dictionary created")

    start_time = time.time()
    train_dataset = h5py.File("train_data.hdf5", "w")
    dset = train_dataset.create_dataset("clear_image", data=d["clear_image_patch"], compression=comp, shuffle=shuff)
    dset = train_dataset.create_dataset("transmission_value", data=d["transmission_values"], compression=comp, shuffle=shuff)
    dset = train_dataset.create_dataset("haze_image", data=d["haze_image_patch"], compression=comp, shuffle=shuff)
    train_dataset.close()
    print("--- %s seconds in creating dataset ---" % (time.time() - start_time))
    print("compression:", dset.compression, " compression_opt:", dset.compression_opts, " shuffle:", dset.shuffle, " size:", os.stat("train_data.hdf5").st_size)
    print("Dataset created")

import h5py  # Add this import for HDF5 file handling
import time
from google.colab import drive
import os
import cv2
import numpy as np
from sklearn.feature_extraction import image as sk_image
import random

create_train_dataset(count = 1200, patch_count = 50)

import h5py
import matplotlib.pyplot as plt  # Add this import for matplotlib

# prints the keys of the datasets stored in the HDF5 file i.e. clear_image, haze_image, transmission_value
temp = h5py.File('train_data.hdf5', 'r')
print(temp.keys())
plt.imshow(temp['clear_image'][1000])
plt.show()
plt.imshow(temp['haze_image'][1000])
plt.show()
print(temp['transmission_value'][1000])
print(temp['clear_image'].shape,temp['haze_image'].shape,len(temp['transmission_value']))
temp.close()

# this will save this model in the drive
!cp '/content/train_data.hdf5' '/content/drive/My Drive/DL Project/Datasets/TrainData/train_data_patch_16x16.hdf5'

file = '/content/drive/My Drive/DL Project/Datasets/TrainData/train_data_patch_16x16.hdf5'
train_dataset = h5py.File(file, 'r')
clean_image = np.array(train_dataset['clear_image'][:])
haze_image = np.array(train_dataset['haze_image'][:])
transmission_value = np.array(train_dataset['transmission_value'])

print ("number of training examples:", clean_image.shape[0])
print ("Clean Image Patch shape:", clean_image.shape)
print ("Haze Image Patch shape:", haze_image.shape)

"""***Keras simplifies the design, training, and deployment of neural networks for complex tasks like image dehazing. It provides a powerful yet easy-to-use framework that enables developers to efficiently build models for processing images and extracting relevant features. In this specific case, Keras is used to define a CNN model that estimates transmission maps, a crucial step in dehazing images.***"""

# TransmissionModel: Defines a CNN that estimates the transmission map from hazy images.
# Guidedfilter: Implements a guided filter that smooths and refines the transmission map.
# TransmissionRefine: Uses the guided filter to improve the estimated transmission map by aligning it with the image's structure.
def TransmissionModel(input_shape):
    """
    Returns:
    model -- a Model() instance in Keras
    """

    X_input = Input(input_shape, name = 'input1')

    # CONV -> RELU Block applied to X
    X = Conv2D(16, (3, 3), strides = (1, 1), name = 'conv1')(X_input)
    X = Activation('relu', name = 'activation1')(X)

    # SLICE Block applied to X
    X1 = Lambda(lambda X: X[:,:,:,:4], name = 'slice1')(X)
    X2 = Lambda(lambda X: X[:,:,:,4:8], name = 'slice2')(X)
    X3 = Lambda(lambda X: X[:,:,:,8:12], name = 'slice3')(X)
    X4 = Lambda(lambda X: X[:,:,:,12:], name = 'slice4')(X)

    # MAXIMUM Block applied to 4 slices
    X = Maximum(name = 'merge1_maximum')([X1,X2,X3,X4])

    # CONV BLock for multi-scale mapping with filters of size 3x3, 5x5, 7x7
    X_3x3 = Conv2D(16, (3, 3), strides = (1, 1), padding = 'same', name = 'conv2_3x3')(X)
    X_5x5 = Conv2D(16, (5, 5), strides = (1, 1), padding = 'same', name = 'conv2_5x5')(X)
    X_7x7 = Conv2D(16, (7, 7), strides = (1, 1), padding = 'same', name = 'conv2_7x7')(X)

    # CONCATENATE Block to join 3 multi-scale layers
    X = Concatenate(name = 'merge2_concatenate')([X_3x3,X_5x5,X_7x7])

    # MAXPOOL layer of filter size 7x7
    X = MaxPooling2D((7, 7), strides = (1, 1), name = 'maxpool1')(X)

    # CONV -> RELU BLock
    X = Conv2D(1, (8, 8), strides = (1, 1), name = 'conv3')(X)
    X = Activation('relu', name = 'activation2')(X)

    # Create Keras model instance
    model = Model(inputs = X_input, outputs = X, name='TransmissionModel')

    return model

def Guidedfilter(im,p,r,eps):
	mean_I = cv2.boxFilter(im,cv2.CV_64F,(r,r))
	mean_p = cv2.boxFilter(p, cv2.CV_64F,(r,r))
	mean_Ip = cv2.boxFilter(im*p,cv2.CV_64F,(r,r))
	cov_Ip = mean_Ip - mean_I*mean_p
	mean_II = cv2.boxFilter(im*im,cv2.CV_64F,(r,r))
	var_I   = mean_II - mean_I*mean_I
	a = cov_Ip/(var_I + eps)
	b = mean_p - a*mean_I
	mean_a = cv2.boxFilter(a,cv2.CV_64F,(r,r))
	mean_b = cv2.boxFilter(b,cv2.CV_64F,(r,r))
	q = mean_a*im + mean_b
	return q

def TransmissionRefine(im,et):
	gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)
	gray = np.float64(gray)/255
	r = 60
	eps = 0.0001
	t = Guidedfilter(gray,et,r,eps)
	return t

import numpy as np
import cv2
import h5py
import random
from sklearn.feature_extraction import image as sk_image
from keras.layers import Input, Conv2D, Activation, Lambda, Maximum, Concatenate, MaxPooling2D
from keras.models import Model

tm_model = TransmissionModel((31,31,3))
tm_model.summary()

# Example assuming the weights file is in the same directory as your notebook
tm_model = TransmissionModel((31,31,3))
tm_model.load_weights('/content/drive/My Drive/DL Project/Datasets/transmodel_100_20_weights.h5')
c = np.pad(haze_image, ((0,0), (7,8), (7,8), (0,0)), 'symmetric')
nyu_transmission_map = tm_model.predict(c)

# Check the shape of nyu_transmission_map
print("Shape of nyu_transmission_map:", nyu_transmission_map.shape)

# Calculate the number of elements in the original array
num_elements = np.prod(nyu_transmission_map.shape)
print("Number of elements in nyu_transmission_map:", num_elements)

# Calculate the number of elements required by the target shape (60000, 16, 16)
target_shape_elements = 60000 * 16 * 16
print("Number of elements in target shape (60000, 16, 16):", target_shape_elements)

# Adjust the reshaping if the number of elements matches
if num_elements == target_shape_elements:
    b = nyu_transmission_map.reshape(60000, 16, 16)
    d = (haze_image * 255.0).astype('uint8')
    for i, val in enumerate(b):
        b[i] = TransmissionRefine(d[i], val)
else:
    # Use the correct reshaping based on the available number of elements
    b = nyu_transmission_map.reshape(14050, 16, 16)
    d = (haze_image * 255.0).astype('uint8')
    for i, val in enumerate(b):
        b[i] = TransmissionRefine(d[i], val)

# Assuming you have already loaded the model and made predictions
tm_model = TransmissionModel((31,31,3))
tm_model.load_weights('/content/drive/My Drive/DL Project/Datasets/transmodel_100_20_weights.h5')
c = np.pad(haze_image,((0,0), (7,8), (7,8), (0,0)), 'symmetric')
nyu_transmission_map = tm_model.predict(c)
m = nyu_transmission_map.reshape(14050, 16, 16)
 # Assuming this is how you reshape it

# Now you can visualize the images
for i in range(10):
    plt.imshow(clean_image[i])
    plt.title(f"Clean Image {i}")
    plt.show()

    plt.imshow(haze_image[i])
    plt.title(f"Haze Image {i}")
    plt.show()

    plt.imshow(m[i])
    plt.title(f"Transmission Map {i}")
    plt.show()

    plt.imshow(b[i])
    plt.title(f"Refined Transmission Map {i}")
    plt.show()

train_dataset = h5py.File("mj.hdf5", "w")
train_dataset.create_dataset("clear_image",data = clean_image,compression=9,shuffle=True)
train_dataset.create_dataset("transmission_map",data = m,compression=9,shuffle=True)
train_dataset.create_dataset("transmission_map_refine",data = b,compression=9,shuffle=True)
train_dataset.create_dataset("haze_image",data = haze_image,compression=9,shuffle=True)
train_dataset.close()

"""# **Testdata** pre-processing"""

from google.colab import drive
drive.mount('/content/gdrive')

import os, random

from PIL import Image
from matplotlib import pyplot as plt

!unzip -q '/content/gdrive/My Drive/DL Project/Datasets/TestData/ITS/clear.zip' -d '/content/'

!unzip -q '/content/gdrive/My Drive/DL Project/Datasets/TestData/ITS/haze.zip' -d '/content/'

clear = os.listdir('clear')
haze = os.listdir('haze')

!mkdir test_its

rhaze = random.sample(haze, 20)
for i in range(len(rhaze)):
    im = Image.open('haze/'+rhaze[i])
    c = rhaze[i].partition('_')[0]+'.png'
    im_c = Image.open('clear/'+c)
    # plt.imshow(im_c)
    # plt.show()
    # plt.imshow(im)
    # plt.show()
    im_c.save('test_its/'+str(i)+'_clean.jpg')
    im.save('test_its/'+str(i)+'.jpg')

!ls test_its | wc -l

!tar -czvf test_its.tar.gz test_its

!cp test_its.tar.gz '/content/gdrive/My Drive/DL Project/Datasets/TestData'

"""**network model residual**"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import h5py
import math
import os

from keras.models import Model
from keras.layers import Input, Activation, BatchNormalization, Conv2D, Conv3D
from keras.layers import Lambda, Concatenate, MaxPooling2D, Maximum, Add
from keras.initializers import RandomNormal
from keras.optimizers import SGD
from keras.losses import MeanSquaredError
from keras.callbacks import Callback,LearningRateScheduler
from keras.utils import plot_model

import keras.backend as K
K.set_image_data_format('channels_last')

import matplotlib.pyplot as plt
from matplotlib.pyplot import imshow

# %matplotlib inline

import h5py
import numpy as np

def load_train_dataset():
    """
    Load training dataset from Google Drive

    Returns:
    clean_image -- Clean image patches
    haze_image -- Hazy image patches
    transmission_value -- Transmission value which converts clean image to haze image
    """
    file = '/content/drive/My Drive/DL Project/Datasets/TrainData/train_data_patch_16x16.hdf5'
    with h5py.File(file, 'r') as train_dataset:
        clean_image = np.array(train_dataset['clear_image'][:])
        haze_image = np.array(train_dataset['haze_image'][:])
        transmission_map = np.array(train_dataset['transmission_value'][:])
        transmission_map_refine = np.array(train_dataset['transmission_value'][:])  # Adjust if there's a different refined map

    return clean_image, haze_image, transmission_map, transmission_map_refine


# Gaussian Weight Initializtion for layers
weight_init = RandomNormal(mean=0.0, stddev=0.001)


# LearningRate Decay function
def lr_schedule(epoch,lr, logs={}):
    """
    Learning Rate Deacy scheduler

    Arguments:
    epoch -- current epoch number
    lr -- current learning rate
    log -- dictionary storing the logs of training

    Returns:
    lr -- learning rate for next epoch
    """

    print('learning_rate:',lr)
    logs.update({'lr': lr})
    if epoch in (49,99):
        return lr*0.5
    else:
        return lr

try:
    clean_image, haze_image, transmission_map, transmission_map_refine = load_train_dataset()
    print("Number of training examples:", clean_image.shape[0])
    print("Clean Image Patch shape:", clean_image.shape)
    print("Haze Image Patch shape:", haze_image.shape)
    print("Transmission Map shape:", transmission_map.shape)
    print("Transmission Map Refine shape:", transmission_map_refine.shape)
except KeyError as e:
    print(f"Error: {e}")

# residual_input = np.clip(((haze_image/255.0)/np.expand_dims(transmission_map_refine,axis=3)),0,1)
# residual_output = np.clip((residual_input-clean_image),0,1)

import numpy as np

# Print the shapes to understand the issue
print("Shape of haze_image:", haze_image.shape)
print("Shape of transmission_map_refine:", transmission_map_refine.shape)

# Assuming each transmission_map_refine corresponds to a single haze_image
# Reshape and expand dimensions to make it compatible
transmission_map_refine_expanded = transmission_map_refine[:, np.newaxis, np.newaxis, np.newaxis]

# Broadcast transmission_map_refine to match the spatial dimensions of haze_image
transmission_map_refine_expanded = np.tile(transmission_map_refine_expanded, (1, haze_image.shape[1], haze_image.shape[2], 1))

# Clip the values and calculate residual_input and residual_output
residual_input = np.clip((haze_image / 255.0) / transmission_map_refine_expanded, 0, 1)
residual_output = np.clip(residual_input - clean_image, 0, 1)

"""The ResidualModel refines the output to ensure better haze removal.Means this will work after we creates the haze free image."""

def ResidualBlock(X, iter):
    """
    Implementation of the single block of RNN

    Arguments:
    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)
    iter -- integer, used to name layers, depending on current residual block

    Returns:
    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)
    """

    # Save the input value
    X_shortcut = X

    # BATCHNORMALIZATION -> CONV Block
    X = BatchNormalization(axis = 3, name = 'res_batchnorm_' + str(iter))(X)
    X = Conv2D(1, (3, 3), strides = (1,1), padding = 'same', kernel_initializer = weight_init, name = 'res_conv_' + str(iter))(X)

    # Add shortcut value to main path, and pass it through a RELU activation
    X = Add(name = 'res_add_'+ str(iter))([X,X_shortcut])
    X = Activation('relu', name = 'res_activation_'+ str(iter))(X)

    return X

def ResidualModel(input_shape):
    """
    Implementation of the Model.

    Arguments:
    input_shape -- shape of the images of the dataset
                   (height, width, channels) as a tuple.

    Returns:
    model -- a Model() instance in Keras
    """

    X_input = Input(input_shape, name = 'input1')

    # CONV -> RELU Block applied to X
    X = Conv2D(16, (3, 3), strides = (1, 1), padding = 'same', kernel_initializer = weight_init, name = 'conv1')(X_input)
    X = Activation('relu', name = 'activation1')(X)

    # X = Conv2D(8, (1, 1), kernel_initializer = weight_init, name='test_conv')(X)

    for i in range(17):
        X = ResidualBlock(X, i)

    # CONV BLock
    X = Conv2D(3, (3, 3), strides = (1, 1), padding = 'same', kernel_initializer = weight_init, name = 'conv2')(X)
    X = Activation('relu', name = 'activation2')(X)

    # Create Keras model instance
    model = Model(inputs = X_input, outputs = X, name='TransmissionModel')

    return model

model2 = ResidualModel(residual_input.shape[1:])
model2.summary()
model2.compile(optimizer=SGD(0.001), loss=MeanSquaredError())

history2 = model2.fit(residual_input, residual_output, batch_size = 30, epochs = 150, callbacks=[LearningRateScheduler(lr_schedule)])

t = np.expand_dims(residual_input[7], axis=0)
T = model2.predict(t)
plt.imshow(residual_input[7]-T[0])
plt.show()
plt.imshow(clean_image[7])
plt.show()
plt.imshow(haze_image[7])
plt.show()

"""**Transmission model - The TransmissionModel learns to predict the transmission map for each hazy image.**"""

from google.colab import drive
drive.mount('/content/drive')

# !tar -xzvf '/content/drive/My Drive/DL Project/Datasets/TestData/test.tar.gz'
!cp '/content/drive/My Drive/DL Project/Model & Weights/Weights/resmodel_weights.h5' '/content'
!cp '/content/drive/My Drive/DL Project/Model & Weights/Weights/transmodel_weights.h5' '/content'

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import h5py
import math


from keras.models import Model
from keras.layers import Input, Activation, BatchNormalization, Conv2D, Conv3D
from keras.layers import Lambda, Concatenate, MaxPooling2D, Maximum, Add
from keras.initializers import RandomNormal
from tensorflow.keras.optimizers import schedules, SGD
from keras.callbacks import Callback
from keras.utils import plot_model

import keras.backend as K
K.set_image_data_format('channels_last')

import matplotlib.pyplot as plt
from matplotlib.pyplot import imshow

from PIL import Image

import cv2

# %matplotlib inline

def Guidedfilter(im,p,r,eps):
	mean_I = cv2.boxFilter(im,cv2.CV_64F,(r,r))
	mean_p = cv2.boxFilter(p, cv2.CV_64F,(r,r))
	mean_Ip = cv2.boxFilter(im*p,cv2.CV_64F,(r,r))
	cov_Ip = mean_Ip - mean_I*mean_p
	mean_II = cv2.boxFilter(im*im,cv2.CV_64F,(r,r))
	var_I   = mean_II - mean_I*mean_I
	a = cov_Ip/(var_I + eps)
	b = mean_p - a*mean_I
	mean_a = cv2.boxFilter(a,cv2.CV_64F,(r,r))
	mean_b = cv2.boxFilter(b,cv2.CV_64F,(r,r))
	q = mean_a*im + mean_b
	return q

def TransmissionRefine(im,et):
	gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)
	gray = np.float64(gray)/255
	r = 60
	eps = 0.0001
	t = Guidedfilter(gray,et,r,eps)
	return t

def TransmissionModel(input_shape):

    X_input = Input(input_shape, name = 'input1')

    # CONV -> RELU Block applied to X
    X = Conv2D(16, (3, 3), strides = (1, 1), name = 'conv1')(X_input)
    X = Activation('relu', name = 'activation1')(X)

    # SLICE Block applied to X
    X1 = Lambda(lambda X: X[:,:,:,:4], name = 'slice1')(X)
    X2 = Lambda(lambda X: X[:,:,:,4:8], name = 'slice2')(X)
    X3 = Lambda(lambda X: X[:,:,:,8:12], name = 'slice3')(X)
    X4 = Lambda(lambda X: X[:,:,:,12:], name = 'slice4')(X)

    # MAXIMUM Block applied to 4 slices
    X = Maximum(name = 'merge1_maximum')([X1,X2,X3,X4])

    # CONV BLock for multi-scale mapping with filters of size 3x3, 5x5, 7x7
    X_3x3 = Conv2D(16, (3, 3), strides = (1, 1), padding = 'same', name = 'conv2_3x3')(X)
    X_5x5 = Conv2D(16, (5, 5), strides = (1, 1), padding = 'same', name = 'conv2_5x5')(X)
    X_7x7 = Conv2D(16, (7, 7), strides = (1, 1), padding = 'same', name = 'conv2_7x7')(X)

    # CONCATENATE Block to join 3 multi-scale layers
    X = Concatenate(name = 'merge2_concatenate')([X_3x3,X_5x5,X_7x7])

    # MAXPOOL layer of filter size 7x7
    X = MaxPooling2D((7, 7), strides = (1, 1), name = 'maxpool1')(X)

    # CONV -> RELU BLock
    X = Conv2D(1, (8, 8), strides = (1, 1), name = 'conv3')(X)
    X = Activation('relu', name = 'activation2')(X)

    # Create Keras model instance
    model = Model(inputs = X_input, outputs = X, name='TransmissionModel')

    return model

"""from where we are getting clear image for the residual function??
From this relation
in this we are not considering effect of airlight so assuming it to be 1

In the formula above, I(x) is the hazy image, and we aim to solve for J(x) (the clear image). Rearranging the formula, we get:

ùêΩ
(
ùë•
)
=
(ùêº
(
ùë•
)
‚àí
ùê¥
‚ãÖ
(
1
‚àí
ùëá
(
ùë•
))
)
/
ùëá
(
ùë•
)
"""

def dehaze_image(img_name):
    input_image_orig = np.asarray(Image.open(img_name))/255.0
    input_image = np.pad(input_image_orig,((7,8), (7,8), (0,0)),'symmetric')

    model = TransmissionModel(input_image.shape)
    model.load_weights('/content/drive/MyDrive/DL Project/Model & Weights/Weights/transmodel_weights.h5')

    input_image = np.expand_dims(input_image, axis=0)
    trans_map_orig = model.predict(input_image)
    trans_map = trans_map_orig.reshape(input_image_orig.shape[:2])
    trans_map_refine = TransmissionRefine((input_image_orig*255.0).astype('uint8'),trans_map)

    res_map_input = input_image_orig/np.expand_dims(trans_map_refine, axis=(0,3))

    model = ResidualModel(res_map_input.shape[1:])
    model.load_weights('/content/drive/MyDrive/DL Project/Model & Weights/Weights/resmodel_weights.h5')
    res_map_output = model.predict(np.clip(res_map_input,0,1))

    haze_free_image = (res_map_input-res_map_output)
    haze_free_image = np.clip(haze_free_image,0,1)

    return haze_free_image[0]

out = dehaze_image('/content/drive/My Drive/DL Project/Model & Weights/Weights/cones.jpg')
plt.imshow(out)

for i in range(20):
    out = dehaze_image('/content/drive/My Drive/DL Project/Results/out1/'+str(i)+'.jpg')
    plt.imsave(('/content/drive/My Drive/DL Project/Results/out1/'+str(i)+'_dehaze.png'),out)

input_image_orig = np.asarray(Image.open('/content/drive/My Drive/DL Project/Results/out1/3.jpg'))/255.0
input_image = np.pad(input_image_orig,((7,8), (7,8), (0,0)),'symmetric')

model = TransmissionModel(input_image.shape)
# model.summary()
model.load_weights('transmodel_weights.h5')

input_image = np.expand_dims(input_image, axis=0)
trans_map_orig = model.predict(input_image)
trans_map = trans_map_orig.reshape(input_image_orig.shape[:2])
trans_map_refine = TransmissionRefine((input_image_orig*255.0).astype('uint8'),trans_map)

res_map_input = input_image_orig/np.expand_dims(trans_map_refine, axis=(0,3))

model = ResidualModel(res_map_input.shape[1:])
model.load_weights('resmodel_weights.h5')
res_map_output = model.predict(np.clip(res_map_input,0,1))

haze_free_image = (res_map_input-res_map_output)
haze_free_image = np.clip(haze_free_image,0,1)

print('Input Image')
plt.imshow(input_image_orig)
plt.show()

print('Transmission Map')
plt.imshow(trans_map)
plt.show()

print('Refined Transmission Map')
plt.imshow(trans_map_refine)
plt.show()

print('Residual Model Input Image')
plt.imshow(np.clip(res_map_input[0],0,1))
plt.show()

print('Residual Model Output Image')
plt.imshow(np.clip(res_map_output[0],0,1))
plt.show()

print('Generated Haze Free Image')
plt.imshow(haze_free_image[0])
plt.show()

"""**Average SSIM: 0.976609305807616**"""

from google.colab import drive
drive.mount('/content/drive')

#Atmospheric Scattering Model

# Dark Channel Prior for estimating haze density.
# Atmospheric light and transmission map for haze removal.
# Radiance recovery to generate the dehazed output.

import numpy as np
import cv2
from skimage.metrics import structural_similarity as ssim
import matplotlib.pyplot as plt

def dark_channel_prior(img, size=15):
    """Calculate the dark channel of the image."""
    dark_channel = cv2.min(cv2.min(img[:, :, 0], img[:, :, 1]), img[:, :, 2])
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (size, size))
    dark_channel = cv2.erode(dark_channel, kernel)
    return dark_channel

def estimate_atmospheric_light(img, dark_channel):
    """Estimate the atmospheric light using the dark channel."""
    h, w = img.shape[:2]
    num_pixels = h * w
    top_pixels = int(max(num_pixels * 0.001, 1))  # Use the top 0.1% of brightest pixels

    # Flatten the dark channel and get indices of sorted intensities
    flat_dark = dark_channel.ravel()
    indices = np.argsort(flat_dark)[-top_pixels:]

    # Use the brightest pixels in the dark channel to estimate atmospheric light
    brightest_pixels = img.reshape(-1, 3)[indices]
    atmospheric_light = np.max(brightest_pixels, axis=0)

    return atmospheric_light

def estimate_transmission(img, atmospheric_light, omega=0.95, size=15):
    """Estimate the transmission map using the dark channel prior."""
    normalized_img = img / atmospheric_light
    transmission = 1 - omega * dark_channel_prior(normalized_img, size)
    return transmission

def recover_radiance(img, transmission, atmospheric_light, t0=0.1):
    """Recover the scene radiance (dehazed image)."""
    transmission = np.maximum(transmission, t0)  # Prevent division by zero
    recovered_img = np.zeros_like(img)

    for i in range(3):
        recovered_img[:, :, i] = (img[:, :, i] - atmospheric_light[i]) / transmission + atmospheric_light[i]

    recovered_img = np.clip(recovered_img, 0, 255)
    return recovered_img.astype(np.uint8)

def dehaze_image(img):
    """Perform the dehazing process on an image."""
    # Estimate the dark channel
    dark_channel = dark_channel_prior(img)

    # Estimate atmospheric light
    atmospheric_light = estimate_atmospheric_light(img, dark_channel)

    # Estimate transmission map
    transmission = estimate_transmission(img, atmospheric_light)

    # Recover the dehazed image
    dehazed_img = recover_radiance(img, transmission, atmospheric_light)

    return dehazed_img, transmission

def calculate_ssim(original, dehazed):
    """Calculate the Structural Similarity Index (SSIM) between the original and dehazed image."""
    original_gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)
    dehazed_gray = cv2.cvtColor(dehazed, cv2.COLOR_BGR2GRAY)
    ssim_value = ssim(original_gray, dehazed_gray, data_range=dehazed_gray.max() - dehazed_gray.min())
    return ssim_value

# Load a hazy image
hazy_image = cv2.imread('/content/drive/MyDrive/Colab Notebooks/0001_0.8_0.2.jpg')
hazy_image = cv2.cvtColor(hazy_image, cv2.COLOR_BGR2RGB)

# Perform dehazing
dehazed_image, transmission_map = dehaze_image(hazy_image)

# Calculate SSIM (assuming we have a corresponding clear image)
clear_image = cv2.imread('/content/drive/MyDrive/Colab Notebooks/0001.png')
clear_image = cv2.cvtColor(clear_image, cv2.COLOR_BGR2RGB)

ssim_value = calculate_ssim(clear_image, dehazed_image)
print(f'SSIM between clear and dehazed image: {ssim_value:.4f}')

# Display the images
plt.figure(figsize=(15, 5))
plt.subplot(1, 3, 1)
plt.title('Hazy Image')
plt.imshow(hazy_image)
plt.axis('off')

plt.subplot(1, 3, 2)
plt.title('Dehazed Image')
plt.imshow(dehazed_image)
plt.axis('off')

plt.subplot(1, 3, 3)
plt.title('Transmission Map')
plt.imshow(transmission_map, cmap='gray')
plt.axis('off')

plt.tight_layout()
plt.show()

#clahe
# Convert hazy image to LAB color space.
# Apply CLAHE on the L channel to enhance local contrast.
# Recombine the modified L channel with the A and B channels.
# Convert the enhanced LAB image back to RGB.

# ability to separate color (chromaticity) from brightness (luminance)
# L (Lightness): Represents the brightness of the color.
# A (Green-Red Chromatic Component)
# B (Blue-Yellow Chromatic Component)

import cv2
import numpy as np
from skimage.metrics import structural_similarity as ssim
import matplotlib.pyplot as plt

def apply_clahe(img, clip_limit=2.0, tile_grid_size=(8, 8)):
    """Apply CLAHE to the input image."""
    # Convert to LAB color space
    lab = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)

    # Split the LAB image into L, A and B channels
    l_channel, a_channel, b_channel = cv2.split(lab)

    # Create a CLAHE object
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)

    # Apply CLAHE to the L channel
    cl = clahe.apply(l_channel)

    # Merge the CLAHE enhanced L channel with the A and B channels
    enhanced_lab = cv2.merge((cl, a_channel, b_channel))

    # Convert back to BGR color space
    enhanced_img = cv2.cvtColor(enhanced_lab, cv2.COLOR_Lab2BGR)

    return enhanced_img

def calculate_ssim(original, enhanced):
    """Calculate the Structural Similarity Index (SSIM) between the original and enhanced image."""
    original_gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)
    enhanced_gray = cv2.cvtColor(enhanced, cv2.COLOR_BGR2GRAY)
    ssim_value = ssim(original_gray, enhanced_gray, data_range=enhanced_gray.max() - enhanced_gray.min())
    return ssim_value

# Load a hazy image
hazy_image = cv2.imread('/content/drive/MyDrive/Colab Notebooks/0001_0.8_0.2.jpg')
hazy_image = cv2.cvtColor(hazy_image, cv2.COLOR_BGR2RGB)

# Apply CLAHE
clahe_enhanced_image = apply_clahe(hazy_image)

# Calculate SSIM (assuming we have a corresponding clear image)
clear_image = cv2.imread('/content/drive/MyDrive/Colab Notebooks/0001.png')
clear_image = cv2.cvtColor(clear_image, cv2.COLOR_BGR2RGB)

ssim_value = calculate_ssim(clear_image, clahe_enhanced_image)
print(f'SSIM between clear and CLAHE enhanced image: {ssim_value:.4f}')

# Display the images
plt.figure(figsize=(15, 5))
plt.subplot(1, 3, 1)
plt.title('Hazy Image')
plt.imshow(hazy_image)
plt.axis('off')

plt.subplot(1, 3, 2)
plt.title('CLAHE Enhanced Image')
plt.imshow(clahe_enhanced_image)
plt.axis('off')

plt.subplot(1, 3, 3)
plt.title('Original Clear Image')
plt.imshow(clear_image)
plt.axis('off')

plt.tight_layout()
plt.show()

